{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66bdee8",
   "metadata": {},
   "source": [
    "# Inquinamento Amat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af7f82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from shapely import Point\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89dc7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAW\n",
    "PATH_STAZIONI_RAW = \"../Data/Raw/Inquinamento/Amat/inquinamento-amat_stazioni_raw.csv\"\n",
    "PATH_INQUINANTI_RAW = \"../Data/Raw/Inquinamento/Amat/inquinamento-amat_inquinanti_raw.csv\"\n",
    "PATH_INGESTION_AMAT_RAW = \"../Data/Raw/Inquinamento/Amat/inquinamento-amat_ingestion_raw.json\"\n",
    "PATH_SOGLIE_RAW = \"../Data/Raw/Inquinamento/Amat/inquinamento-amat_soglie_raw.csv\"\n",
    "\n",
    "# STAGING\n",
    "PATH_BOLLETTINO_STAGING = \"../Data/Staging/Inquinamento/Amat/inquinamento-amat_bollettino_staging.csv\"\n",
    "PATH_MISURAZIONI_STAGING = \"../Data/Staging/Inquinamento/Amat/inquinamento-amat_misurazioni_staging.csv\"\n",
    "\n",
    "# CLEAN\n",
    "PATH_MISURAZIONI_CLEAN = \"../Data/Clean/Inquinamento/Amat/inquinamento-amat_misurazioni_clean.csv\"\n",
    "PATH_BOLLETTINO_CLEAN = \"../Data/Clean/Inquinamento/Amat/inquinamento-amat_bollettino_clean.csv\"\n",
    "PATH_STAZIONI_CLEAN = \"../Data/Clean/Inquinamento/Amat/inquinamento-amat_stazioni_clean.csv\"\n",
    "PATH_INQUINANTI_CLEAN = \"../Data/Clean/Inquinamento/Amat/inquinamento-amat_inquinanti_clean.csv\"\n",
    "PATH_SOGLIE_CLEAN = \"../Data/Clean/Inquinamento/Amat/inquinamento-amat_soglie_clean.csv\"\n",
    "PATH_SQLITE_DB_CLEAN = \"../Data/Clean/Inquinamento/Amat/inquinamento-amat_sqlite-db_clean.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0db5e6",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf8a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping progress...: 100%|██████████| 365/365 [02:12<00:00,  3.30it/s]"
     ]
    }
   ],
   "source": [
    "#Scraper functions\n",
    "\n",
    "def _get_table_row_values(row:Tag) -> dict:\n",
    "    \"\"\"\n",
    "    Return a dict like: {\"pollutant\": value, (...)}\n",
    "    \"\"\"\n",
    "    inquinanti = [\n",
    "        \"Biossido di Zolfo\",\n",
    "        \"Polveri < 10\",\n",
    "        \"Polveri < 2.5\",\n",
    "        \"Biossido di Azoto\",\n",
    "        \"Monossido di carbonio\",\n",
    "        \"Ozono\",\n",
    "        \"Benzene\"\n",
    "    ]\n",
    "    cells = row.select(\"td\")[1:]\n",
    "    row_value = {}\n",
    "    for pollutant, cell in zip(inquinanti, cells):\n",
    "        row_value[pollutant] = cell.text\n",
    "    return row_value\n",
    "\n",
    "def get_table_day_values(day: datetime) -> dict | None:\n",
    "    \"\"\"\n",
    "    Return a dict like: {\"station_address\": {\"pollutant\": value, (...)}, (...)}\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://www.amat-mi.it/index.php?id_sezione=35&data_bollettino={day.year}-{day.month}-{day.day}\"\n",
    "    main_page = requests.get(url)\n",
    "    main_page = BeautifulSoup(main_page.text)\n",
    "    table = main_page.select_one(\".table\")\n",
    "    if not table:\n",
    "        return None\n",
    "\n",
    "    table_values = {}\n",
    "    stations = [\n",
    "        \"Viale Liguria\",\n",
    "        \"Viale Marche\",\n",
    "        \"Via Pascal\",\n",
    "        \"Via Senato\",\n",
    "        \"Verziere\"\n",
    "    ]\n",
    "    rows = table.select(\"tr\")[2:7]\n",
    "    for station, row in zip(stations, rows):\n",
    "        table_values[station] = _get_table_row_values(row)\n",
    "    return table_values\n",
    "\n",
    "def get_days_list(start: datetime, end: datetime):\n",
    "    numdays = (end - start).days\n",
    "    return [start + timedelta(days=x) for x in range(numdays + 1)]\n",
    "\n",
    "# Other functions\n",
    "\n",
    "def pad2(day_or_month: int) -> str:\n",
    "    response = str(day_or_month)\n",
    "    if len(response) > 1:\n",
    "        return response\n",
    "    return f\"0{response}\"\n",
    "\n",
    "days = get_days_list(datetime(2023, 1, 1), datetime(2023, 12, 31))\n",
    "db = []\n",
    "pbar = tqdm(total=len(days), desc=\"Scraping progress...\")\n",
    "for day in days:\n",
    "    table_value = get_table_day_values(day)\n",
    "    if table_value:\n",
    "        db.append({\"Date\": f\"{day.year}-{pad2(day.month)}-{pad2(day.day)}\", \"Stations\": table_value})\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8536d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_INGESTION_AMAT_RAW, \"w\") as file:\n",
    "    json.dump(db, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedea8d",
   "metadata": {},
   "source": [
    "### Normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f962b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw files to normalizations\n",
    "\n",
    "with open(PATH_INGESTION_AMAT_RAW, 'r') as file:\n",
    "    ingestion:list = json.load(file)\n",
    "stations = pd.read_csv(PATH_STAZIONI_RAW)\n",
    "inquinanti_df = pd.read_csv(PATH_INQUINANTI_RAW)\n",
    "\n",
    "# Start operations\n",
    "bollettino_csv = [[\"id_bollettino\", \"data\"]]\n",
    "misurazione_csv = [[\"id_bollettino\", \"id_stazione\", \"id_inquinante\", \"valore\"]]\n",
    "for i, rilevation in enumerate(ingestion):\n",
    "    id_bollettino = i + 1\n",
    "    bollettino_csv.append([id_bollettino, rilevation[\"Date\"]])\n",
    "    for nome_stazione, inquinanti in rilevation[\"Stations\"].items():\n",
    "        id_station = stations[stations[\"nome\"] == nome_stazione][\"id_stazione\"].values[0]\n",
    "        for nome_inquinante, valore in inquinanti.items():\n",
    "            id_inquinante = inquinanti_df[inquinanti_df[\"nome\"] == nome_inquinante][\"id_inquinante\"].values[0]\n",
    "            misurazione_csv.append([id_bollettino, id_station, id_inquinante, valore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf67ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(bollettino_csv).to_csv(PATH_BOLLETTINO_STAGING, index=False, header=False)\n",
    "pd.DataFrame(misurazione_csv).to_csv(PATH_MISURAZIONI_STAGING, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386cf41",
   "metadata": {},
   "source": [
    "## ELT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ef4af",
   "metadata": {},
   "source": [
    "### Pulizia tabella misurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bf3eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_valore(x):\n",
    "    valore = x.strip(\"\\n\").strip(\"\\r\").strip().replace(\",\", \".\")\n",
    "    try:\n",
    "        valore = float(valore)\n",
    "    except:\n",
    "        if \"<\" in valore:\n",
    "            valore = 0.0\n",
    "        else:\n",
    "            valore = None\n",
    "    return valore\n",
    "\n",
    "misurazione = gpd.read_file(PATH_MISURAZIONI_STAGING)\n",
    "\n",
    "misurazione[\"valore\"] = misurazione[\"valore\"].apply(lambda_valore)\n",
    "misurazione = misurazione[misurazione[\"valore\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e52de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "misurazione.to_csv(PATH_MISURAZIONI_CLEAN, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd5f57",
   "metadata": {},
   "source": [
    "### Pulizia tabelle e caricamento in Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1755bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nessuna pulizia necessaria al momento. Carico direttamente.\n",
    "\n",
    "gpd.read_file(PATH_BOLLETTINO_STAGING).to_csv(PATH_BOLLETTINO_CLEAN, encoding='latin',index=False)\n",
    "\n",
    "gpd.read_file(PATH_STAZIONI_RAW).to_csv(PATH_STAZIONI_CLEAN, encoding='latin', index=False)\n",
    "\n",
    "gpd.read_file(PATH_INQUINANTI_RAW).to_csv(PATH_INQUINANTI_CLEAN, encoding='latin', index=False)\n",
    "\n",
    "gpd.read_file(PATH_SOGLIE_RAW).to_csv(PATH_SOGLIE_CLEAN, encoding='latin', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb664d80",
   "metadata": {},
   "source": [
    "Creazione Geojson con medie annue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1dfc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tabella_media_inquinanti(id_inquinante:int, nome_valore:str):\n",
    "    \n",
    "    inquinanti = gpd.pd.read_csv(PATH_INQUINANTI_CLEAN, encoding=\"latin\")\n",
    "    stazioni = gpd.pd.read_csv(PATH_STAZIONI_CLEAN, encoding=\"latin\")\n",
    "    misurazioni = gpd.pd.read_csv(PATH_MISURAZIONI_CLEAN, encoding=\"latin\")\n",
    "    misurazioni = misurazioni.rename(columns={\"valore\": nome_valore})\n",
    "    bollettino = gpd.pd.read_csv(PATH_BOLLETTINO_CLEAN, encoding=\"latin\")\n",
    "    bollettino[\"data\"] = gpd.pd.to_datetime(bollettino[\"data\"])\n",
    "\n",
    "    df = misurazioni[misurazioni[\"id_inquinante\"] == id_inquinante]\n",
    "    df = df.merge(inquinanti, on=\"id_inquinante\", how=\"left\")\n",
    "    df = df.merge(bollettino, on=\"id_bollettino\", how=\"left\")\n",
    "    df = df.merge(stazioni, on=\"id_stazione\", how=\"left\", suffixes=(\"_pm10\", \"_stazione\"))\n",
    "    colonne = [nome_valore, \"data\", \"simbolo\", \"nome_stazione\", \"latitude\", \"longitute\"]\n",
    "    df = df[colonne]\n",
    "\n",
    "    df = df.groupby(\"nome_stazione\").mean(\"valore\").reset_index()\n",
    "    return df\n",
    "\n",
    "df_pm10 = get_tabella_media_inquinanti(2, \"valore_pm10\")\n",
    "df_pm25 = get_tabella_media_inquinanti(3, \"valore_pm25\")\n",
    "df_NO2 = get_tabella_media_inquinanti(4, \"valore_NO2\")\n",
    "\n",
    "final_df = df_pm10.merge(df_pm25[[\"nome_stazione\", \"valore_pm25\"]], on=\"nome_stazione\", how=\"left\" \\\n",
    "                         ).merge(df_NO2[[\"nome_stazione\", \"valore_NO2\"]], on=\"nome_stazione\", how=\"left\")\n",
    "final_df = final_df[[\"valore_pm10\", \"valore_pm25\", \"valore_NO2\", \"nome_stazione\", \"latitude\", \"longitute\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b6a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"geometry\"] = final_df.apply(lambda row: Point(row[\"longitute\"], row[\"latitude\"]), axis=1)\n",
    "PATH_INQUINANTI_AMAT_GEOJSON_CLEAN = \"../Data/Clean/Inquinamento/Amat/inquinamento-amat_media_clean.geojson\"\n",
    "gpd.GeoDataFrame(final_df, geometry=\"geometry\", crs=\"EPSG:6707\").to_file(PATH_INQUINANTI_AMAT_GEOJSON_CLEAN, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c276e8",
   "metadata": {},
   "source": [
    "## Creation SQLITE DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_schema_table(drop_command:str, create_command:str, insert_command:str, rows :list[tuple]) -> list[str]:\n",
    "\n",
    "    for row in rows:\n",
    "        insert_command = insert_command + \"(\"\n",
    "        for element in row:\n",
    "            if isinstance(element, str):\n",
    "                element = \"'\" + element + \"'\"\n",
    "            insert_command = insert_command + f\"{element},\"\n",
    "        insert_command = insert_command.strip(\",\") + \"),\"\n",
    "    insert_command = insert_command.strip(\",\") + \";\"\n",
    "\n",
    "    return [drop_command, create_command, insert_command]\n",
    "\n",
    "def execute_query_list(queries: list[str]):\n",
    "    response = []\n",
    "    with sqlite3.connect(PATH_SQLITE_DB_CLEAN) as connection:\n",
    "        for query in queries:\n",
    "            cursor = connection.cursor()\n",
    "            result = cursor.execute(query)\n",
    "            response.append(result.fetchall())\n",
    "            connection.commit()\n",
    "    return response\n",
    "\n",
    "tables = {}\n",
    "# set commands tables\n",
    "tables[\"bollettino\"] = {\n",
    "    \"commands\":{\n",
    "        \"drop\": \"DROP TABLE IF EXISTS bollettino;\",\n",
    "        \"create\": \"\"\"CREATE TABLE bollettino (\"id_bollettino\" INT PRIMARY KEY,\"data\" DATE NULL);\"\"\",\n",
    "        \"insert\": \"\"\"INSERT INTO bollettino (\"id_bollettino\",\"data\") VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "tables[\"stazione\"] = {\n",
    "    \"commands\": {\n",
    "        \"drop\": \"DROP TABLE IF EXISTS stazione;\",\n",
    "        \"create\": \"\"\"\n",
    "            CREATE TABLE stazione (\n",
    "                \"id_stazione\" INT PRIMARY KEY,\n",
    "                \"nome\" VARCHAR(255) NULL,\n",
    "                \"latitude\" NUMERIC NULL,\n",
    "                \"longitute\" NUMERIC NULL\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"insert\":\"\"\"INSERT INTO stazione (\"id_stazione\",\"nome\",\"latitude\",\"longitute\") VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "tables[\"inquinante\"] = {\n",
    "    \"commands\": {\n",
    "        \"drop\": \"DROP TABLE IF EXISTS inquinante;\",\n",
    "        \"create\": \"\"\"\n",
    "            CREATE TABLE inquinante (\n",
    "                \"id_inquinante\" INT PRIMARY KEY,\n",
    "                \"nome\" VARCHAR(255) NULL,\n",
    "                \"simbolo\" VARCHAR(255) NULL,\n",
    "                \"unita_di_misura\" VARCHAR(255) NULL,\n",
    "                \"media_temporale\" VARCHAR(255) NULL\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"insert\":\"\"\"INSERT INTO inquinante (\"id_inquinante\",\"nome\",\"simbolo\",\"unita_di_misura\",\"media_temporale\") VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "tables[\"misurazione\"] = {\n",
    "    \"commands\": {\n",
    "        \"drop\": \"\"\"DROP TABLE IF EXISTS misurazione;\"\"\",\n",
    "        \"create\": \"\"\"\n",
    "            CREATE TABLE misurazione (\n",
    "                \"id_bollettino\" INT NOT NULL,\n",
    "                \"id_stazione\" INT NOT NULL,\n",
    "                \"id_inquinante\" INT NOT NULL,\n",
    "                \"valore\" NUMERIC NULL,\n",
    "                FOREIGN KEY(id_bollettino) REFERENCES bollettino(id_bollettino),\n",
    "                FOREIGN KEY(id_stazione) REFERENCES stazione(id_stazione),\n",
    "                FOREIGN KEY(id_inquinante) REFERENCES inquinante(id_inquinante)\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"insert\": \"\"\"INSERT INTO misurazione (\"id_bollettino\",\"id_stazione\",\"id_inquinante\",\"valore\") VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "tables[\"soglia\"] = {\n",
    "    \"commands\": {\n",
    "        \"drop\": \"\"\"DROP TABLE IF EXISTS soglia;\"\"\",\n",
    "        \"create\": \"\"\"\n",
    "            CREATE TABLE soglia (\n",
    "                \"id_inquinante\" INT NOT NULL,\n",
    "                \"tipo_soglia\" VARCHAR(255) NULL,\n",
    "                \"valore\" INT NULL,\n",
    "                \"unita_di_misura\" VARCHAR(255) NULL,\n",
    "                \"periodo_di_riferimento\" VARCHAR(255) NULL,\n",
    "                \"max_superamenti_anno\" INT NULL\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"insert\": \"\"\"INSERT INTO soglia (\n",
    "                        \"id_inquinante\",\n",
    "                        \"tipo_soglia\",\n",
    "                        \"valore\",\n",
    "                        \"unita_di_misura\",\n",
    "                        \"periodo_di_riferimento\",\n",
    "                        \"max_superamenti_anno\"\n",
    "                    ) VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# set rows from df\n",
    "tables[\"bollettino\"][\"rows\"] = list(pd.read_csv(PATH_BOLLETTINO_CLEAN).itertuples(index=False, name=None))\n",
    "tables[\"stazione\"][\"rows\"] = list(pd.read_csv(PATH_STAZIONI_CLEAN).itertuples(index=False, name=None))\n",
    "tables[\"inquinante\"][\"rows\"] = list(pd.read_csv(PATH_INQUINANTI_CLEAN).itertuples(index=False, name=None))\n",
    "tables[\"misurazione\"][\"rows\"] = list(pd.read_csv(PATH_MISURAZIONI_CLEAN).itertuples(index=False, name=None))\n",
    "tables[\"soglia\"][\"rows\"] = list(pd.read_csv(PATH_SOGLIE_CLEAN).itertuples(index=False, name=None))\n",
    "\n",
    "# Create schema query\n",
    "total_query = []\n",
    "for v in tables.values():\n",
    "    total_query.extend(get_schema_table(v[\"commands\"][\"drop\"], v[\"commands\"][\"create\"], v[\"commands\"][\"insert\"], v[\"rows\"]))\n",
    "\n",
    "# Execute query\n",
    "query_result = execute_query_list(total_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef12bf",
   "metadata": {},
   "source": [
    "# Inquinamento Airnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cd24381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "import requests\n",
    "from sseclient import SSEClient\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170c6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAW\n",
    "PATH_INQUINAMENTO_INGESTION_RAW = \"../Data/Raw/Inquinamento/Airnet/inquinamento-airnet_media_raw.geojson\"\n",
    "\n",
    "# STAGING\n",
    "\n",
    "# CLEAN\n",
    "PATH_INQUINAMENTO_INGESTION_CLEAN = \"../Data/Clean/Inquinamento/Airnet/inquinamento-airnet_ingestion_clean.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb69a02b",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ec67ee",
   "metadata": {},
   "source": [
    "Otteniamo gli id delle stazioni di Milano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f47ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://airnet.waqi.info/airnet/validator/check/112273\" # Una stazione a caso di milano\\\n",
    "risposta = requests.get(URL)\n",
    "risposta_json = risposta.json()\n",
    "neighbors = risposta_json[\"data\"][\"neighbors\"]  # Da questa riusciamo a ricavare tutte le stazioni \"vicine\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c909b97",
   "metadata": {},
   "source": [
    "inizializziamo il geojson con id e coordinate delle stazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78cac211",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"name\": \"Inquinamento\",\n",
    "    \"crs\": {\n",
    "        \"type\": \"name\",\n",
    "        \"properties\": {\n",
    "            \"name\": \"urn:ogc:def:crs:EPSG::6707\"\n",
    "        }\n",
    "    },\n",
    "    \"features\": []\n",
    "}\n",
    "for geo, id in zip(neighbors[\"geos\"], neighbors[\"ids\"]):\n",
    "    if not id == 353767: # Stazione marco emme, Milan, Italy che non contiene dati pm10 e pm25\n",
    "        geojson[\"features\"].append(\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\n",
    "                    \"id\": id,\n",
    "                    \"longitudine\": geo[1],\n",
    "                    \"latitudine\": geo[0],\n",
    "                    \"name\": \"\",\n",
    "                    \"pm10\": [],\n",
    "                    \"pm25\": []\n",
    "                },\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Point\",\n",
    "                    \"coordinates\": [geo[1], geo[0]]\n",
    "                }\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3b0e2",
   "metadata": {},
   "source": [
    "Estraiamo i dati di ogni stazione (per i 2 inquinanti) e li inseriamo direttamente tra le \"features\" >> \"properties\" del geojson inizializzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2598976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping progress...: 100%|██████████| 19/19 [01:17<00:00,  4.18s/it]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(geojson[\"features\"]), desc=\"Scraping progress...\")\n",
    "\n",
    "for feature in geojson[\"features\"]:\n",
    "    for inquinante in [\"pm10\", \"pm25\"]:\n",
    "        url = f\"https://airnet.waqi.info/airnet/sse/historic/daily/{feature[\"properties\"][\"id\"]}?specie={inquinante}\"\n",
    "        response = requests.get(url, params={\"specie\": inquinante}, headers={\"Accept\": \"text/event-stream\"}, stream=True)\n",
    "        client = SSEClient(response)\n",
    "        for i, event in enumerate(client.events()):\n",
    "            if event.event != \"error\":\n",
    "                try:\n",
    "                    data = json.loads(event.data)\n",
    "                    if i == 0:\n",
    "                        feature[\"properties\"][\"name\"] = data[\"meta\"][\"name\"]\n",
    "                    elif isinstance(data, dict): #Ogni tanto ci sono righe sporche di stringhe\n",
    "                        feature[\"properties\"][inquinante].append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Errore JSON:\", event.data)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c8257",
   "metadata": {},
   "source": [
    "salvo il file geojson creato in Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "548c45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_INQUINAMENTO_INGESTION_RAW, 'w') as file:\n",
    "    json.dump(geojson, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3db842",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8d807",
   "metadata": {},
   "source": [
    "A partire dai dati giornalieri dei 2 inquinanti (pm10 e pm25) ricaviamo gli aggregati per anno sottoforma di media delle mediane giornaliere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28682f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_mean_pm(row):\n",
    "    for pm in [\"pm10\", \"pm25\"]:\n",
    "        df = gpd.pd.read_json(StringIO(row[pm]))\n",
    "        df[\"day\"] = gpd.pd.to_datetime(df[\"day\"])\n",
    "        df = df[df['day'].dt.year.isin([2023])].reset_index()\n",
    "        if len(df) > 200:\n",
    "            row[pm] = df[\"median\"].mean()\n",
    "        else:\n",
    "            row[pm] = None\n",
    "    return row\n",
    "\n",
    "gdf = gpd.read_file(PATH_INQUINAMENTO_INGESTION_RAW)\n",
    "gdf = gpd.GeoDataFrame(gdf.apply(set_mean_pm, axis=1), geometry=gdf.geometry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd823e5",
   "metadata": {},
   "source": [
    "Salviamo su Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96fbce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(PATH_INQUINAMENTO_INGESTION_CLEAN, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da54d657",
   "metadata": {},
   "source": [
    "# Join dei 2 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e37b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb84020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INQUINAMENTO_JOINED_CLEAN = \"../Data/Clean/Inquinamento/inquinamento_media_clean.geojson\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
