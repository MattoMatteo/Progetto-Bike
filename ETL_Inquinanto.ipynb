{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66bdee8",
   "metadata": {},
   "source": [
    "# INGESTION + ETL + DB Inquinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0db5e6",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf8a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping progress...: 100%|██████████| 365/365 [02:57<00:00,  2.62it/s]"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Scraper functions\n",
    "\n",
    "def _get_table_row_values(row:Tag) -> dict:\n",
    "    \"\"\"\n",
    "    Return a dict like: {\"pollutant\": value, (...)}\n",
    "    \"\"\"\n",
    "    inquinanti = [\n",
    "        \"Biossido di Zolfo\",\n",
    "        \"Polveri < 10\",\n",
    "        \"Polveri < 2.5\",\n",
    "        \"Biossido di Azoto\",\n",
    "        \"Monossido di carbonio\",\n",
    "        \"Ozono\",\n",
    "        \"Benzene\"\n",
    "    ]\n",
    "    cells = row.select(\"td\")[1:]\n",
    "    row_value = {}\n",
    "    for pollutant, cell in zip(inquinanti, cells):\n",
    "        row_value[pollutant] = cell.text\n",
    "    return row_value\n",
    "\n",
    "def get_table_day_values(day: datetime) -> dict | None:\n",
    "    \"\"\"\n",
    "    Return a dict like: {\"station_address\": {\"pollutant\": value, (...)}, (...)}\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://www.amat-mi.it/index.php?id_sezione=35&data_bollettino={day.year}-{day.month}-{day.day}\"\n",
    "    main_page = requests.get(url)\n",
    "    main_page = BeautifulSoup(main_page.text)\n",
    "    table = main_page.select_one(\".table\")\n",
    "    if not table:\n",
    "        return None\n",
    "\n",
    "    table_values = {}\n",
    "    stations = [\n",
    "        \"Viale Liguria\",\n",
    "        \"Viale Marche\",\n",
    "        \"Via Pascal\",\n",
    "        \"Via Senato\",\n",
    "        \"Verziere\"\n",
    "    ]\n",
    "    rows = table.select(\"tr\")[2:7]\n",
    "    for station, row in zip(stations, rows):\n",
    "        table_values[station] = _get_table_row_values(row)\n",
    "    return table_values\n",
    "\n",
    "def get_days_list(start: datetime, end: datetime):\n",
    "    numdays = (end - start).days\n",
    "    return [start + timedelta(days=x) for x in range(numdays + 1)]\n",
    "\n",
    "# Other functions\n",
    "\n",
    "def pad2(day_or_month: int) -> str:\n",
    "    response = str(day_or_month)\n",
    "    if len(response) > 1:\n",
    "        return response\n",
    "    return f\"0{response}\"\n",
    "\n",
    "days = get_days_list(datetime(2023, 1, 1), datetime(2023, 12, 31))\n",
    "db = []\n",
    "pbar = tqdm(total=len(days), desc=\"Scraping progress...\")\n",
    "for day in days:\n",
    "    table_value = get_table_day_values(day)\n",
    "    if table_value:\n",
    "        db.append({\"Date\": f\"{day.year}-{pad2(day.month)}-{pad2(day.day)}\", \"Stations\": table_value})\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8536d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OUT = \"./Data/Raw/Inquinamento/inquinamento.json\"\n",
    "with open(PATH_OUT, \"w\") as file:\n",
    "    json.dump(db, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedea8d",
   "metadata": {},
   "source": [
    "### Normalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f962b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load raw files to normalizations\n",
    "PATH_RELEVATIONS = \"./Data/Raw/Inquinamento/inquinamento.json\"\n",
    "PATH_STATIONS = \"./Data/Raw/Inquinamento/inquinamento_stazione.csv\"\n",
    "PATH_MOLECULE = \"./Data/Raw/Inquinamento/inquinamento_inquinante.csv\"\n",
    "\n",
    "with open(PATH_RELEVATIONS, 'r') as file:\n",
    "    rilevations:list = json.load(file)\n",
    "stations = pd.read_csv(PATH_STATIONS)\n",
    "inquinanti_df = pd.read_csv(PATH_MOLECULE)\n",
    "\n",
    "# Start operations\n",
    "bollettino_csv = [[\"id_bollettino\", \"data\"]]\n",
    "misurazione_csv = [[\"id_bollettino\", \"id_stazione\", \"id_inquinante\", \"valore\"]]\n",
    "for i, rilevation in enumerate(rilevations):\n",
    "    id_bollettino = i + 1\n",
    "    bollettino_csv.append([id_bollettino, rilevation[\"Date\"]])\n",
    "    for nome_stazione, inquinanti in rilevation[\"Stations\"].items():\n",
    "        id_station = stations[stations[\"nome\"] == nome_stazione][\"id_stazione\"].values[0]\n",
    "        for nome_inquinante, valore in inquinanti.items():\n",
    "            id_inquinante = inquinanti_df[inquinanti_df[\"nome\"] == nome_inquinante][\"id_inquinante\"].values[0]\n",
    "            misurazione_csv.append([id_bollettino, id_station, id_inquinante, valore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf67ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BOLLETTINO_OUT = \"./Data/Raw/Inquinamento/bollettino.csv\"\n",
    "PATH_MISURAZIONE_OUT = \"./Data/Raw/Inquinamento/misurazione.csv\"\n",
    "pd.DataFrame(bollettino_csv).to_csv(PATH_BOLLETTINO_OUT, index=False, header=False)\n",
    "pd.DataFrame(misurazione_csv).to_csv(PATH_MISURAZIONE_OUT, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386cf41",
   "metadata": {},
   "source": [
    "## ELT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ef4af",
   "metadata": {},
   "source": [
    "### Pulizia tabella misurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf3eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def lambda_valore(x):\n",
    "    valore = x.strip(\"\\n\").strip(\"\\r\").strip().replace(\",\", \".\")\n",
    "    try:\n",
    "        valore = float(valore)\n",
    "    except:\n",
    "        if \"<\" in valore:\n",
    "            valore = 0.0\n",
    "        else:\n",
    "            valore = None\n",
    "    return valore\n",
    "\n",
    "PATH_MISURAZIONE = \"./Data/Raw/Inquinamento/misurazione.csv\"\n",
    "\n",
    "misurazione = pd.read_csv(PATH_MISURAZIONE)\n",
    "\n",
    "misurazione[\"valore\"] = misurazione[\"valore\"].apply(lambda_valore)\n",
    "misurazione = misurazione[misurazione[\"valore\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e52de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MISURAZIONE_OUT = \"./Data/Clean/Inquinamento/inquinamento_misurazione_clean.csv\"\n",
    "misurazione.to_csv(PATH_MISURAZIONE_OUT, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd5f57",
   "metadata": {},
   "source": [
    "### Pulizia tabelle e caricamento in Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nessuna pulizia necessaria al momento. Carico direttamente.\n",
    "\n",
    "PATH_BOLLETTINO = \"./Data/Raw/Inquinamento/bollettino.csv\"\n",
    "PATH_BOLLETTINO_OUT = \"./Data/Clean/Inquinamento/inquinamento_bollettino_clean.csv\"\n",
    "pd.read_csv(PATH_BOLLETTINO).to_csv(PATH_BOLLETTINO_OUT, index=False)\n",
    "\n",
    "PATH_STAZIONE = \"./Data/Raw/Inquinamento/inquinamento_stazione.csv\"\n",
    "PATH_STAZIONE_OUT = \"./Data/Clean/Inquinamento/inquinamento_stazione_clean.csv\"\n",
    "pd.read_csv(PATH_STAZIONE).to_csv(PATH_STAZIONE_OUT, index=False)\n",
    "\n",
    "PATH_INQUINANTE = \"./Data/Raw/Inquinamento/inquinamento_inquinante.csv\"\n",
    "PATH_INQUINANTE_OUT = \"./Data/Clean/Inquinamento/inquinamento_inquinante_clean.csv\"\n",
    "pd.read_csv(PATH_INQUINANTE).to_csv(PATH_INQUINANTE_OUT, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c276e8",
   "metadata": {},
   "source": [
    "## Creation SQLITE DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c0a6399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_schema_table(drop_command:str, create_command:str, insert_command:str, rows :list[tuple]) -> list[str]:\n",
    "\n",
    "    for row in rows:\n",
    "        insert_command = insert_command + \"(\"\n",
    "        for element in row:\n",
    "            if isinstance(element, str):\n",
    "                element = \"'\" + element + \"'\"\n",
    "            insert_command = insert_command + f\"{element},\"\n",
    "        insert_command = insert_command.strip(\",\") + \"),\"\n",
    "    insert_command = insert_command.strip(\",\") + \";\"\n",
    "\n",
    "    return [drop_command, create_command, insert_command]\n",
    "\n",
    "def execute_query_list(queries: list[str]):\n",
    "    response = []\n",
    "    with sqlite3.connect(PATH_DB) as connection:\n",
    "        for query in queries:\n",
    "            cursor = connection.cursor()\n",
    "            result = cursor.execute(query)\n",
    "            response.append(result.fetchall())\n",
    "            connection.commit()\n",
    "    return response\n",
    "\n",
    "# Set file paths\n",
    "PATH_DB = \"./Data/Clean/Inquinamento/inquinamento.db\"\n",
    "PATH_BOLLETTINO_CLEAN = \"./Data/Clean/Inquinamento/inquinamento_bollettino_clean.csv\"\n",
    "PATH_STAZIONE_CLEAN = \"./Data/Clean/Inquinamento/inquinamento_stazione_clean.csv\"\n",
    "PATH_INQUINANTE_CLEAN = \"./Data/Clean/Inquinamento/inquinamento_inquinante_clean.csv\"\n",
    "PATH_MISURAZIONE_CLEAN = \"./Data/Clean/Inquinamento/inquinamento_misurazione_clean.csv\"\n",
    "PATH_SOGLIA_CLEAN = \"./Data/Clean/Inquinamento/inquinamento_soglia_clean.csv\"\n",
    "\n",
    "tables = {}\n",
    "# set commands tables\n",
    "tables[\"bollettino\"] = {\n",
    "    \"commands\":{\n",
    "        \"drop\": \"DROP TABLE IF EXISTS bollettino;\",\n",
    "        \"create\": \"\"\"CREATE TABLE bollettino (\"id_bollettino\" INT PRIMARY KEY,\"data\" DATE NULL);\"\"\",\n",
    "        \"insert\": \"\"\"INSERT INTO bollettino (\"id_bollettino\",\"data\") VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "tables[\"stazione\"] = {\n",
    "    \"commands\": {\n",
    "        \"drop\": \"DROP TABLE IF EXISTS stazione;\",\n",
    "        \"create\": \"\"\"\n",
    "            CREATE TABLE stazione (\n",
    "                \"id_stazione\" INT PRIMARY KEY,\n",
    "                \"nome\" VARCHAR(255) NULL,\n",
    "                \"latitude\" NUMERIC NULL,\n",
    "                \"longitute\" NUMERIC NULL\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"insert\":\"\"\"INSERT INTO stazione (\"id_stazione\",\"nome\",\"latitude\",\"longitute\") VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "tables[\"inquinante\"] = {\n",
    "    \"commands\": {\n",
    "        \"drop\": \"DROP TABLE IF EXISTS inquinante;\",\n",
    "        \"create\": \"\"\"\n",
    "            CREATE TABLE inquinante (\n",
    "                \"id_inquinante\" INT PRIMARY KEY,\n",
    "                \"nome\" VARCHAR(255) NULL,\n",
    "                \"simbolo\" VARCHAR(255) NULL,\n",
    "                \"unita_di_misura\" VARCHAR(255) NULL,\n",
    "                \"media_temporale\" VARCHAR(255) NULL\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"insert\":\"\"\"INSERT INTO inquinante (\"id_inquinante\",\"nome\",\"simbolo\",\"unita_di_misura\",\"media_temporale\") VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "tables[\"misurazione\"] = {\n",
    "    \"commands\": {\n",
    "        \"drop\": \"\"\"DROP TABLE IF EXISTS misurazione;\"\"\",\n",
    "        \"create\": \"\"\"\n",
    "            CREATE TABLE misurazione (\n",
    "                \"id_bollettino\" INT NOT NULL,\n",
    "                \"id_stazione\" INT NOT NULL,\n",
    "                \"id_inquinante\" INT NOT NULL,\n",
    "                \"valore\" NUMERIC NULL,\n",
    "                FOREIGN KEY(id_bollettino) REFERENCES bollettino(id_bollettino),\n",
    "                FOREIGN KEY(id_stazione) REFERENCES stazione(id_stazione),\n",
    "                FOREIGN KEY(id_inquinante) REFERENCES inquinante(id_inquinante)\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"insert\": \"\"\"INSERT INTO misurazione (\"id_bollettino\",\"id_stazione\",\"id_inquinante\",\"valore\") VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "tables[\"soglia\"] = {\n",
    "    \"commands\": {\n",
    "        \"drop\": \"\"\"DROP TABLE IF EXISTS soglia;\"\"\",\n",
    "        \"create\": \"\"\"\n",
    "            CREATE TABLE soglia (\n",
    "                \"id_inquinante\" INT NOT NULL,\n",
    "                \"tipo_soglia\" VARCHAR(255) NULL,\n",
    "                \"valore\" INT NULL,\n",
    "                \"unita_di_misura\" VARCHAR(255) NULL,\n",
    "                \"periodo_di_riferimento\" VARCHAR(255) NULL,\n",
    "                \"max_superamenti_anno\" INT NULL\n",
    "            );\n",
    "        \"\"\",\n",
    "        \"insert\": \"\"\"INSERT INTO soglia (\n",
    "                        \"id_inquinante\",\n",
    "                        \"tipo_soglia\",\n",
    "                        \"valore\",\n",
    "                        \"unita_di_misura\",\n",
    "                        \"periodo_di_riferimento\",\n",
    "                        \"max_superamenti_anno\"\n",
    "                    ) VALUES\\n\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# set rows from df\n",
    "tables[\"bollettino\"][\"rows\"] = list(pd.read_csv(PATH_BOLLETTINO_CLEAN).itertuples(index=False, name=None))\n",
    "tables[\"stazione\"][\"rows\"] = list(pd.read_csv(PATH_STAZIONE_CLEAN).itertuples(index=False, name=None))\n",
    "tables[\"inquinante\"][\"rows\"] = list(pd.read_csv(PATH_INQUINANTE_CLEAN).itertuples(index=False, name=None))\n",
    "tables[\"misurazione\"][\"rows\"] = list(pd.read_csv(PATH_MISURAZIONE_CLEAN).itertuples(index=False, name=None))\n",
    "tables[\"soglia\"][\"rows\"] = list(pd.read_csv(PATH_SOGLIA_CLEAN).itertuples(index=False, name=None))\n",
    "\n",
    "# Create schema query\n",
    "total_query = []\n",
    "for v in tables.values():\n",
    "    total_query.extend(get_schema_table(v[\"commands\"][\"drop\"], v[\"commands\"][\"create\"], v[\"commands\"][\"insert\"], v[\"rows\"]))\n",
    "\n",
    "# Execute query\n",
    "query_result = execute_query_list(total_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef12bf",
   "metadata": {},
   "source": [
    "# Nuovo Inquinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH_NUOVO_INQUINAMENTO = \"./Data/Raw/Inquinamento/nuovo_inquinamento.csv\"\n",
    "df = pd.read_csv(PATH_NUOVO_INQUINAMENTO)\n",
    "\n",
    "df = df.sort_values(\"time\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f47ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "URL = \"https://airnet.waqi.info/airnet/validator/check/66889\"\n",
    "payload = {\"data\": {\"stats\": {\"periods\": [\"2025-07-01T10:00:00+01:00\",\"2025-07-19T10:00:00+01:00\"]} }}\n",
    "risposta = requests.get(URL, params=payload)\n",
    "risposta_json = risposta.json()\n",
    "risposta_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
